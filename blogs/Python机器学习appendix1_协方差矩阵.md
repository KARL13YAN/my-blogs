# Python机器学习读书笔记（九）——协方差矩阵

---

> 前面的几篇关于降维的文章中（[PCA](http://blog.csdn.net/weixin_40604987/article/details/79598125)、[LDA](http://blog.csdn.net/weixin_40604987/article/details/79615968)、[kPCA](http://blog.csdn.net/weixin_40604987/article/details/79632888)），多次提到了协方差矩阵，协方差矩阵简直就是一个绕不过去的坑！于是捋了捋《Python机器学习》和《机器学习》这两本书以及一些博客，准备写一写协方差矩阵。

## **协方差矩阵的引入**

首先介绍统计学中的几个相关基础概念，包括均值、标准差、方差。

### **统计学中的基本概念**

- 给定的数据样本是$X=\{X_1, X_2, ..., X_n\}$

  - **均值**：平均数是表示一组数据集中趋势的量数，是指在一组数据中所有数据之和再除以这组数据的个数。它是反映数据集中趋势的一项指标。

  $$\overline{X} = \frac{\sum_{i=1}^{n}X_i}{n}$$

  - **样本标准差**，标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。（请认准**样本**二字！是除以$n-1$ 而不是 $n$ ！！！）

   $$s=\sqrt{\frac{\sum_{i=1}^{n}{(X_i - \overline{X})^2}}{n-1}}$$

  - **样本方差**，衡量随机变量或一组数据时离散程度的度量，等于标准差的平方（同样的，请认准**样本**二字！是除以$n-1$ 而不是 $n$ ！！！）

$$s^2=\frac{\sum_{i=1}^{n}{(X_i - \overline{X})^2}}{n-1}$$

- 考虑这样两组数字：$[1,5,10,16]$，$[7,9,8,8]$，两者的均值都是 $8$，前者的标准差是 $6.48074$，而后者是 $0.8165$。显然，$[7,9,8,8]$的离散程度小于$[1,5,10,16]$

- **为什么是除以$n-1$**？

  - $[7,9,8,8]$，**样本标准差**是$0.8165$，而**总体标准差**是 $0.70711$。
  - **样本 VS 总体**。通俗的说，样本即是**部分**，总体当然就是那个**总体**。若将给定的一组数据视为**样本**，就要除以n-1，因为这样我们能以样本集的标准差逼近总体的标准差。样本标准差就是统计学上的**无偏估计**。换句话来说，除以n的话，得到的是**有偏估计**。

  - **无偏估计**是用样本统计量来估计总体参数时的一种无偏推断。**估计量的数学期望等于被估计参数的真实值**，则称此此估计量为被估计参数的无偏估计，即具有无偏性，是一种用于评价估计量优良性的准则。无偏估计的意义是：**在多次重复下，它们的平均数接近所估计的参数真值。**

- 然而，上述三个指标都是描述一维数据的......因此引入了**协方差**

## **协方差矩阵的计算**

- **协方差（Covariance**）在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。

- **协方差表示的是两个变量的总体的误差**。 如果**两个变量的变化趋势一致**，那么两个变量之间的协方差就是正值，也就是**正相关**。 如果**两个变量的变化趋势相反**，那么两个变量之间的协方差就是负值，也就是**负相关**。

- $X$与$Y$的协方差可以通过如下公式计算：

$$cov(X,Y)= \frac{\sum_{i=1}^{n}{(X_i - \overline{X})(Y_i - \overline{Y})}}{n-1}$$

### **操作一下**

- 特征矩阵如下，假如我们有两个特征，特征向量为$X=[1, 3]$, 另一个为$Y=[2, 8]$，计算X与Y的协方差

$$W=\begin{bmatrix}
1 &2 \\
3 &8
\end{bmatrix}$$

1. 计算特征向量的均值，$\overline{X}=2$，$\overline{Y}=3$
2. 减去均值
3. $$\begin{bmatrix}
    1 &3 \\
    -1 &-3
    \end{bmatrix}$$

4. 协方差$cov(X,Y)=W^TW$，没错，要把特征向量横着放！
5. $$\begin{bmatrix}
    1 &-1 \\
    3 &-3
    \end{bmatrix}
    \begin{bmatrix}
    1 &3 \\
    -1 &-3
    \end{bmatrix}$$
6. $$\begin{bmatrix}
    2 &6 \\
    6 &18
    \end{bmatrix}$$
7. 结束了吗？**NONONO！**上面这个矩阵还要除以n-1才得到最终结果！
8. n-1=2-1=1，故得到最终的协方差矩阵就是上面这个矩阵。

## **协方差矩阵的Python计算**

- Numpy包可以直接计算协方差矩阵，请注意，np.cov()的实参应该是`arr.T`

```py
import numpy as np

arr = np.array([[1, 2], [3, 8]])

print(np.cov(arr)) # 错误
print(np.cov(arr.T)) # 正确

[[  0.5   2.5]
 [  2.5  12.5]]  # 错误

[[  2.   6.]
 [  6.  18.]] # 正确
```

- 前面提到过，我们所要计算的，是**两个特征之间的协方差**。习惯上，每一行表示一个样本，每一列表由所有样本的某个特征组成。但是在计算协方差时，**特征向量应该横过来**，故调用方式应该是`np.cov(arr.T)`
- 当然，若你的特征已经是“横着放”了，那就不需要逆置矩阵了

---
作者邮箱： mr.yxj@foxmail.com

转载请告知作者，感谢!